{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51189d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d0210d",
   "metadata": {},
   "source": [
    "# Introduction to Convolutional Neural Networks (CNNs)\n",
    "\n",
    "In previous lectures, we've worked with Multi-Layer Perceptrons (MLPs) for image classification tasks. While MLPs can learn to classify images, they have significant limitations:\n",
    "\n",
    "1. **Loss of spatial information**: MLPs flatten the image into a 1D vector, losing the spatial relationships between pixels\n",
    "2. **Parameter explosion**: For high-resolution images, MLPs require huge numbers of parameters (e.g., a 224×224×3 image would need 150,528 weights for just the first layer)\n",
    "3. **No translation invariance**: MLPs don't naturally handle shifted versions of the same pattern\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are specifically designed to address these limitations and have become the standard approach for most computer vision tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090a4022",
   "metadata": {},
   "source": [
    "## Key Building Blocks of CNNs\n",
    "\n",
    "### 1. Convolutional Layers\n",
    "\n",
    "Convolutional layers are the core building block of CNNs. Unlike fully connected layers in MLPs, convolutional layers:\n",
    "\n",
    "- Apply a set of learnable filters (kernels) to the input\n",
    "- Each filter slides (convolves) across the width and height of the input\n",
    "- Compute dot products between the filter weights and the input at each position\n",
    "- Produce a 2D activation map of that filter's responses\n",
    "\n",
    "**Benefits of convolutional layers:**\n",
    "\n",
    "- **Parameter sharing**: The same filter is applied to every position in the image\n",
    "- **Local connectivity**: Each neuron is only connected to a small region of the input\n",
    "- **Translation invariance**: The same feature can be detected regardless of its position\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b18b0c",
   "metadata": {},
   "source": [
    "**Exercise 1:** Create a simple convolution example. Complete the code below to:\n",
    "\n",
    "1. Create a 3×3 edge detection filter\n",
    "2. Apply it to a simple image (a white square on a black background)\n",
    "3. Visualize the input and output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5493878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your task: Complete the code to create a convolution example\n",
    "\n",
    "# Create a simple edge detection filter\n",
    "edge_filter = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            # Your code here: define a 3×3 edge detection filter\n",
    "            # Hint: A common edge detection filter has -1 in all cells except the center, which is 8\n",
    "        ]\n",
    "    )\n",
    "    .float()\n",
    "    .view(1, 1, 3, 3)\n",
    ")  # (out_channels, in_channels, height, width)\n",
    "\n",
    "# Create a simple input (white square on black background)\n",
    "input_image = torch.zeros(1, 1, 8, 8)  # (batch_size, channels, height, width)\n",
    "# Your code here: Set a region in the middle to be white (value 1.0)\n",
    "\n",
    "# Create a convolutional layer with our predefined filter\n",
    "conv_layer = nn.Conv2d(1, 1, kernel_size=3, bias=False)\n",
    "with torch.no_grad():\n",
    "    conv_layer.weight = nn.Parameter(edge_filter)\n",
    "\n",
    "# Apply convolution\n",
    "output = conv_layer(input_image)\n",
    "\n",
    "# Visualize input and output\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].imshow(input_image[0, 0].numpy(), cmap=\"gray\")\n",
    "axes[0].set_title(\"Input Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(output[0, 0].detach().numpy(), cmap=\"gray\")\n",
    "axes[1].set_title(\"After Edge Detection Convolution\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca599c0",
   "metadata": {},
   "source": [
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple edge detection filter\n",
    "edge_filter = (\n",
    "    torch.tensor([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]).float().view(1, 1, 3, 3)\n",
    ")  # (out_channels, in_channels, height, width)\n",
    "\n",
    "# Create a simple input (white square on black background)\n",
    "input_image = torch.zeros(1, 1, 8, 8)  # (batch_size, channels, height, width)\n",
    "input_image[0, 0, 2:6, 2:6] = 1.0  # Set middle 4×4 square to white\n",
    "\n",
    "# Create a convolutional layer with our predefined filter\n",
    "conv_layer = nn.Conv2d(1, 1, kernel_size=3, bias=False)\n",
    "with torch.no_grad():\n",
    "    conv_layer.weight = nn.Parameter(edge_filter)\n",
    "\n",
    "# Apply convolution\n",
    "output = conv_layer(input_image)\n",
    "\n",
    "# Visualize input and output\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].imshow(input_image[0, 0].numpy(), cmap=\"gray\")\n",
    "axes[0].set_title(\"Input Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(output[0, 0].detach().numpy(), cmap=\"gray\")\n",
    "axes[1].set_title(\"After Edge Detection Convolution\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16186396",
   "metadata": {},
   "source": [
    "In this example, the edge detection filter highlights the boundaries of the square. In a CNN, these filters are learned during training rather than being manually defined.\n",
    "\n",
    "**Key parameters in PyTorch's Conv2d layer:**\n",
    "\n",
    "- `kernel_size`: Size of the convolutional filter (e.g., 3×3, 5×5)\n",
    "- `stride`: Step size when sliding the filter (default=1)\n",
    "- `padding`: Zero-padding added to input (default=0)\n",
    "- `in_channels`: Number of input channels\n",
    "- `out_channels`: Number of output channels (number of filters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e5e06",
   "metadata": {},
   "source": [
    "### 2. Pooling Layers\n",
    "\n",
    "Pooling layers reduce the spatial dimensions of the feature maps, which:\n",
    "\n",
    "- Reduces computation in the network\n",
    "- Controls overfitting\n",
    "- Makes the detection more robust to the position of features\n",
    "\n",
    "The most common type is **max pooling**, which takes the maximum value in each window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eedd92f",
   "metadata": {},
   "source": [
    "**Exercise 2:** Implement max pooling. Complete the code below to:\n",
    "\n",
    "1. Create a sample feature map\n",
    "2. Apply max pooling to it\n",
    "3. Visualize the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf49899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your task: Implement max pooling\n",
    "\n",
    "# Create a sample feature map (4×4)\n",
    "feature_map = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            # Your code here: create a 4×4 matrix with some values\n",
    "            # Choose values that will show the effect of max pooling clearly\n",
    "        ]\n",
    "    )\n",
    "    .float()\n",
    "    .view(1, 1, 4, 4)\n",
    ")  # (batch_size, channels, height, width)\n",
    "\n",
    "# Create max pooling layer (2×2 window with stride 2)\n",
    "pool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "# Apply max pooling\n",
    "output = pool_layer(feature_map)\n",
    "\n",
    "# Visualize input and output\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].imshow(feature_map[0, 0].numpy(), cmap=\"viridis\")\n",
    "axes[0].set_title(\"Original Feature Map\")\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[0].text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{feature_map[0, 0, i, j]:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"w\",\n",
    "            fontsize=12,\n",
    "        )\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(output[0, 0].detach().numpy(), cmap=\"viridis\")\n",
    "axes[1].set_title(\"After Max Pooling (2×2)\")\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[1].text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{output[0, 0, i, j]:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"w\",\n",
    "            fontsize=12,\n",
    "        )\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780e8102",
   "metadata": {},
   "source": [
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample feature map (4×4)\n",
    "feature_map = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [1.0, 2.0, 5.0, 6.0],\n",
    "            [3.0, 4.0, 7.0, 8.0],\n",
    "            [9.0, 8.0, 5.0, 4.0],\n",
    "            [7.0, 6.0, 3.0, 2.0],\n",
    "        ]\n",
    "    )\n",
    "    .float()\n",
    "    .view(1, 1, 4, 4)\n",
    ")  # (batch_size, channels, height, width)\n",
    "\n",
    "# Create max pooling layer (2×2 window with stride 2)\n",
    "pool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "# Apply max pooling\n",
    "output = pool_layer(feature_map)\n",
    "\n",
    "# Visualize input and output\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].imshow(feature_map[0, 0].numpy(), cmap=\"viridis\")\n",
    "axes[0].set_title(\"Original Feature Map\")\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[0].text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{feature_map[0, 0, i, j]:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"w\",\n",
    "            fontsize=12,\n",
    "        )\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(output[0, 0].detach().numpy(), cmap=\"viridis\")\n",
    "axes[1].set_title(\"After Max Pooling (2×2)\")\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axes[1].text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{output[0, 0, i, j]:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"w\",\n",
    "            fontsize=12,\n",
    "        )\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9552249c",
   "metadata": {},
   "source": [
    "In this example, the max pooling layer takes a 2×2 window and outputs the maximum value in each window. Note how the output size is reduced from 4×4 to 2×2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35decdfb",
   "metadata": {},
   "source": [
    "### 3. Activation Functions (ReLU)\n",
    "\n",
    "Activation functions introduce non-linearity into the network. The most common activation in CNNs is the Rectified Linear Unit (ReLU), which is defined as:\n",
    "\n",
    "$$f(x) = \\max(0, x)$$\n",
    "\n",
    "ReLU passes through all positive values unchanged and sets all negative values to zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9cfc2",
   "metadata": {},
   "source": [
    "**Exercise 3:** Implement ReLU activation. Complete the code below to:\n",
    "\n",
    "1. Create a feature map with both positive and negative values\n",
    "2. Apply ReLU activation to it\n",
    "3. Visualize the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2383645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your task: Implement ReLU activation\n",
    "\n",
    "# Create a feature map with positive and negative values\n",
    "feature_map = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            # Your code here: create a 4×4 matrix with positive and negative values\n",
    "        ]\n",
    "    )\n",
    "    .float()\n",
    "    .view(1, 1, 4, 4)\n",
    ")  # (batch_size, channels, height, width)\n",
    "\n",
    "# Create ReLU layer\n",
    "relu_layer = nn.ReLU()\n",
    "\n",
    "# Apply ReLU\n",
    "output = relu_layer(feature_map)\n",
    "\n",
    "# Visualize input and output\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "im1 = axes[0].imshow(feature_map[0, 0].numpy(), cmap=\"coolwarm\")\n",
    "axes[0].set_title(\"Original Feature Map\")\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[0].text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{feature_map[0, 0, i, j]:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"k\",\n",
    "            fontsize=12,\n",
    "        )\n",
    "axes[0].axis(\"off\")\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "im2 = axes[1].imshow(output[0, 0].detach().numpy(), cmap=\"coolwarm\")\n",
    "axes[1].set_title(\"After ReLU Activation\")\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[1].text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{output[0, 0, i, j]:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"k\",\n",
    "            fontsize=12,\n",
    "        )\n",
    "axes[1].axis(\"off\")\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d71208f",
   "metadata": {},
   "source": [
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afebc4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature map with positive and negative values\n",
    "feature_map = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [1.0, -2.0, 3.0, -4.0],\n",
    "            [-5.0, 6.0, -7.0, 8.0],\n",
    "            [9.0, -8.0, 7.0, -6.0],\n",
    "            [-5.0, 4.0, -3.0, 2.0],\n",
    "        ]\n",
    "    )\n",
    "    .float()\n",
    "    .view(1, 1, 4, 4)\n",
    ")  # (batch_size, channels, height, width)\n",
    "\n",
    "# Create ReLU layer\n",
    "relu_layer = nn.ReLU()\n",
    "\n",
    "# Apply ReLU\n",
    "output = relu_layer(feature_map)\n",
    "\n",
    "# Visualize input and output\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "im1 = axes[0].imshow(feature_map[0, 0].numpy(), cmap=\"coolwarm\")\n",
    "axes[0].set_title(\"Original Feature Map\")\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[0].text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{feature_map[0, 0, i, j]:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"k\",\n",
    "            fontsize=12,\n",
    "        )\n",
    "axes[0].axis(\"off\")\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "im2 = axes[1].imshow(output[0, 0].detach().numpy(), cmap=\"coolwarm\")\n",
    "axes[1].set_title(\"After ReLU Activation\")\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[1].text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{output[0, 0, i, j]:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"k\",\n",
    "            fontsize=12,\n",
    "        )\n",
    "axes[1].axis(\"off\")\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fdafb9",
   "metadata": {},
   "source": [
    "In this example, ReLU keeps the positive values unchanged but sets all negative values to zero. This non-linearity is crucial for learning complex patterns in deep networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6136265",
   "metadata": {},
   "source": [
    "## Putting It All Together: CNN Architecture\n",
    "\n",
    "A typical CNN consists of several convolutional layers, each followed by ReLU activation, with occasional pooling layers to reduce the spatial dimensions. The final layers are usually fully connected (like in an MLP) for classification.\n",
    "\n",
    "Here's a typical CNN architecture for image classification:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f0bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN architecture diagram\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.axis(\"off\")\n",
    "plt.text(\n",
    "    0.5,\n",
    "    0.5,\n",
    "    \"\"\"\n",
    "Input Image → Conv → ReLU → MaxPool → Conv → ReLU → MaxPool → ... → Flatten → FC → ReLU → FC → Output\n",
    "\"\"\",\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    fontsize=14,\n",
    ")\n",
    "plt.title(\"Typical CNN Architecture\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739b79a",
   "metadata": {},
   "source": [
    "## CIFAR-10 Image Classification Task\n",
    "\n",
    "In this notebook, we'll be working with the CIFAR-10 dataset, which consists of 60,000 32×32 color images across 10 classes:\n",
    "\n",
    "- Airplane\n",
    "- Automobile\n",
    "- Bird\n",
    "- Cat\n",
    "- Deer\n",
    "- Dog\n",
    "- Frog\n",
    "- Horse\n",
    "- Ship\n",
    "- Truck\n",
    "\n",
    "Our goal is to build a CNN that can accurately classify these images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb82a5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load and explore the CIFAR-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=128, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")\n",
    "\n",
    "\n",
    "# Visualize some example images\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# Get random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "plt.figure(figsize=(10, 4))\n",
    "imshow(torchvision.utils.make_grid(images[:8]))\n",
    "plt.axis(\"off\")\n",
    "# Print labels\n",
    "print(\" \".join(\"%5s\" % classes[labels[j]] for j in range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c9c52",
   "metadata": {},
   "source": [
    "## AlexNet Architecture for CIFAR-10\n",
    "\n",
    "Now, we'll implement the AlexNet architecture for CIFAR-10 classification. AlexNet is a pioneering CNN architecture that achieved breakthrough performance on the ImageNet competition in 2012.\n",
    "\n",
    "We've adapted AlexNet to work with the smaller 32×32 CIFAR-10 images while maintaining its key architectural features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7edf1b9",
   "metadata": {},
   "source": [
    "**Exercise 4:** Implement AlexNet for CIFAR-10. Complete the code below to create the AlexNet architecture:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92402694",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Your task: Implement AlexNet for CIFAR-10\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        # TODO: Implement the feature extraction layers\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv1: 64 kernels of size 11×11, stride 4, followed by ReLU\n",
    "            # Modified for CIFAR-10's 32×32 images\n",
    "            # YOUR CODE HERE\n",
    "            # Add more layers according to the AlexNet architecture:\n",
    "            # - Max Pooling after Conv1\n",
    "            # - Conv2 with 192 kernels of size 5×5\n",
    "            # - Max Pooling after Conv2\n",
    "            # - Conv3 with 384 kernels of size 3×3\n",
    "            # - Conv4 with 384 kernels of size 3×3\n",
    "            # - Conv5 with 256 kernels of size 3×3\n",
    "            # - Max Pooling after Conv5\n",
    "            # YOUR CODE HERE\n",
    "        )\n",
    "\n",
    "        # TODO: Implement the classifier (fully connected layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            # FC6: 4096 units + ReLU + Dropout(0.5)\n",
    "            # YOUR CODE HERE\n",
    "            # FC7: 4096 units + ReLU + Dropout(0.5)\n",
    "            # YOUR CODE HERE\n",
    "            # FC8: num_classes units (10 for CIFAR-10)\n",
    "            # YOUR CODE HERE\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement the forward pass\n",
    "        # YOUR CODE HERE\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6739097",
   "metadata": {},
   "source": [
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad5b02",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv1: 64 kernels of size 11×11, stride 4, followed by ReLU\n",
    "            # Modified stride and added padding to work with 32x32 CIFAR-10 images\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=1, padding=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Max Pooling: 3×3 window, stride 2\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            # Conv2: 192 kernels of size 5×5, padding 2, followed by ReLU\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Max Pooling: 3×3 window, stride 2\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            # Conv3: 384 kernels of size 3×3, padding 1, followed by ReLU\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Conv4: 384 kernels of size 3×3, padding 1, followed by ReLU\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Conv5: 256 kernels of size 3×3, padding 1, followed by ReLU\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Max Pooling: 3×3 window, stride 2\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        # Classifier (fully connected layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            # FC6: 4096 units + ReLU + Dropout(0.5)\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 4 * 4, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # FC7: 4096 units + ReLU + Dropout(0.5)\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # FC8: num_classes units (10 for CIFAR-10)\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten the feature maps\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Let's check the model structure\n",
    "model = AlexNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a3766",
   "metadata": {},
   "source": [
    "## Training and Evaluation Functions\n",
    "\n",
    "Now, let's define functions for training our model and evaluating its performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d145c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, testloader, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    \"\"\"\n",
    "    Train the model for a specified number of epochs.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        trainloader: DataLoader for training data\n",
    "        testloader: DataLoader for test data\n",
    "        criterion: Loss function\n",
    "        optimizer: Model optimizer\n",
    "        scheduler: Learning rate scheduler\n",
    "        num_epochs: Number of epochs to train for\n",
    "        \n",
    "    Returns:\n",
    "        train_losses: List of training losses for each epoch\n",
    "        train_accs: List of training accuracies for each epoch\n",
    "        test_losses: List of test losses for each epoch\n",
    "        test_accs: List of test accuracies for each epoch\n",
    "    \"\"\"\n",
    "    # TODO: Initialize lists to store metrics\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # TODO: Train the model for one epoch\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Initialize metrics\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Iterate over batches\n",
    "        loop = tqdm(enumerate(trainloader), total=len(trainloader), leave=False)\n",
    "        for i, (inputs, targets) in loop:\n",
    "            # TODO: Move inputs and targets to device\n",
    "            # TODO: Zero the parameter gradients\n",
    "            # TODO: Forward pass\n",
    "            # TODO: Compute loss\n",
    "            # TODO: Backward pass\n",
    "            # TODO: Optimizer step\n",
    "            # TODO: Update metrics\n",
    "            # TODO: Update progress bar\n",
    "            \n",
    "            # Set model to evaluation mode\n",
    "            model.eval()\n",
    "            \n",
    "            # Initialize test metrics\n",
    "            test_loss = 0.0\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "            \n",
    "            # Disable gradient calculation for evaluation\n",
    "            with torch.no_grad():\n",
    "                # TODO: Iterate over test data\n",
    "                # TODO: Move inputs and targets to device\n",
    "                # TODO: Forward pass\n",
    "                # TODO: Compute loss\n",
    "                # TODO: Update metrics\n",
    "            \n",
    "            # TODO: Calculate epoch metrics\n",
    "            # TODO: Update learning rate\n",
    "            # TODO: Record statistics\n",
    "            # TODO: Print epoch summary\n",
    "            # TODO: Return training and test metrics\n",
    "            \n",
    "    return train_losses, train_accs, test_losses, test_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fcfc77",
   "metadata": {},
   "source": [
    "## Helper Function for Visualizing Conv1 Kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32894d8a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_conv1_kernels(model):\n",
    "    \"\"\"\n",
    "    Plot the kernels of the first convolutional layer.\n",
    "\n",
    "    Args:\n",
    "        model: Trained AlexNet model\n",
    "    \"\"\"\n",
    "    # Extract weights from the first convolutional layer\n",
    "    # Shape is [64, 3, 11, 11] - [out_channels, in_channels, height, width]\n",
    "    weights = model.features[0].weight.data.cpu()\n",
    "\n",
    "    # Normalize weights for better visualization\n",
    "    min_val = weights.min()\n",
    "    max_val = weights.max()\n",
    "    weights = (weights - min_val) / (max_val - min_val)\n",
    "\n",
    "    # Create a grid of all kernels\n",
    "    num_kernels = weights.size(0)\n",
    "    grid_size = int(np.ceil(np.sqrt(num_kernels)))\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "\n",
    "    # Plot each kernel\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < num_kernels:\n",
    "            # Get the kernel and permute dimensions for display\n",
    "            # From [3, 11, 11] (C, H, W) to [11, 11, 3] (H, W, C)\n",
    "            kernel = weights[i].permute(1, 2, 0)\n",
    "\n",
    "            # Display the kernel\n",
    "            ax.imshow(kernel)\n",
    "            ax.axis(\"off\")\n",
    "        else:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"First Convolutional Layer Kernels\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420336d",
   "metadata": {},
   "source": [
    "**Exercise 5:** Complete the training and evaluation functions. Fill in the missing parts in the train_model function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e300c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, testloader, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    \"\"\"\n",
    "    Train the model for a specified number of epochs.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        trainloader: DataLoader for training data\n",
    "        testloader: DataLoader for test data\n",
    "        criterion: Loss function\n",
    "        optimizer: Model optimizer\n",
    "        scheduler: Learning rate scheduler\n",
    "        num_epochs: Number of epochs to train for\n",
    "        \n",
    "    Returns:\n",
    "        train_losses: List of training losses for each epoch\n",
    "        train_accs: List of training accuracies for each epoch\n",
    "        test_losses: List of test losses for each epoch\n",
    "        test_accs: List of test accuracies for each epoch\n",
    "    \"\"\"\n",
    "    # Initialize lists to store metrics\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Initialize metrics\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Iterate over batches\n",
    "        loop = tqdm(enumerate(trainloader), total=len(trainloader), leave=False)\n",
    "        for i, (inputs, targets) in loop:\n",
    "            # TODO: Move inputs and targets to device\n",
    "            \n",
    "            # TODO: Zero the parameter gradients\n",
    "            \n",
    "            # TODO: Forward pass\n",
    "            \n",
    "            # TODO: Compute loss\n",
    "            \n",
    "            # TODO: Backward pass\n",
    "            \n",
    "            # TODO: Optimizer step\n",
    "            \n",
    "            # TODO: Update metrics\n",
    "            \n",
    "            # TODO: Update progress bar\n",
    "        \n",
    "        # Calculate training metrics for this epoch\n",
    "        epoch_train_loss = running_loss / len(trainloader)\n",
    "        epoch_train_acc = 100.0 * correct / total\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in testloader:\n",
    "                # TODO: Move inputs and targets to device\n",
    "                \n",
    "                # TODO: Forward pass\n",
    "                \n",
    "                # TODO: Compute loss\n",
    "                \n",
    "                # TODO: Update metrics\n",
    "        \n",
    "        # Calculate test metrics for this epoch\n",
    "        epoch_test_loss = test_loss / len(testloader)\n",
    "        epoch_test_acc = 100.0 * correct / total\n",
    "        test_losses.append(epoch_test_loss)\n",
    "        test_accs.append(epoch_test_acc)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%, \"\n",
    "              f\"Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_acc:.2f}%\")\n",
    "    \n",
    "    return train_losses, train_accs, test_losses, test_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e61c6c",
   "metadata": {},
   "source": [
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baafd8f4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, trainloader, testloader, criterion, optimizer, scheduler, num_epochs=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model for a specified number of epochs.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        trainloader: DataLoader for training data\n",
    "        testloader: DataLoader for test data\n",
    "        criterion: Loss function\n",
    "        optimizer: Model optimizer\n",
    "        scheduler: Learning rate scheduler\n",
    "        num_epochs: Number of epochs to train for\n",
    "\n",
    "    Returns:\n",
    "        train_losses: List of training losses for each epoch\n",
    "        train_accs: List of training accuracies for each epoch\n",
    "        test_losses: List of test losses for each epoch\n",
    "        test_accs: List of test accuracies for each epoch\n",
    "    \"\"\"\n",
    "    # Initialize lists to store metrics\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "\n",
    "        # Initialize metrics\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Iterate over batches\n",
    "        loop = tqdm(enumerate(trainloader), total=len(trainloader), leave=False)\n",
    "        for i, (inputs, targets) in loop:\n",
    "            # Move inputs and targets to device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            loop.set_postfix(loss=running_loss / (i + 1), acc=100.0 * correct / total)\n",
    "\n",
    "        # Calculate training metrics for this epoch\n",
    "        epoch_train_loss = running_loss / len(trainloader)\n",
    "        epoch_train_acc = 100.0 * correct / total\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in testloader:\n",
    "                # Move inputs and targets to device\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                # Update metrics\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # Calculate test metrics for this epoch\n",
    "        epoch_test_loss = test_loss / len(testloader)\n",
    "        epoch_test_acc = 100.0 * correct / total\n",
    "        test_losses.append(epoch_test_loss)\n",
    "        test_accs.append(epoch_test_acc)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%, \"\n",
    "            f\"Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_acc:.2f}%\"\n",
    "        )\n",
    "\n",
    "    return train_losses, train_accs, test_losses, test_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61e4ee",
   "metadata": {},
   "source": [
    "**Exercise 6:** Train the AlexNet model on CIFAR-10. Complete the code below to:\n",
    "\n",
    "1. Create an instance of the AlexNet model\n",
    "2. Define loss function, optimizer, and learning rate scheduler\n",
    "3. Train the model using the train_model function\n",
    "4. Plot the training and test curves (loss and accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bd2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your task: Train AlexNet on CIFAR-10\n",
    "\n",
    "# TODO: Create an instance of AlexNet\n",
    "\n",
    "# TODO: Define loss function, optimizer, and learning rate scheduler\n",
    "\n",
    "# TODO: Train the model\n",
    "\n",
    "# TODO: Plot the training and test curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dae835",
   "metadata": {},
   "source": [
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc0bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of AlexNet\n",
    "model = AlexNet().to(device)\n",
    "\n",
    "# Define loss function, optimizer, and learning rate scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# Train the model\n",
    "train_losses, train_accs, test_losses, test_accs = train_model(\n",
    "    model, trainloader, testloader, criterion, optimizer, scheduler, num_epochs=5\n",
    ")\n",
    "\n",
    "# Plot the training and test curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, \"b-\", label=\"Train Loss\")\n",
    "plt.plot(range(1, len(test_losses) + 1), test_losses, \"r-\", label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Test Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(train_accs) + 1), train_accs, \"b-\", label=\"Train Accuracy\")\n",
    "plt.plot(range(1, len(test_accs) + 1), test_accs, \"r-\", label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Test Accuracy\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cac07f",
   "metadata": {},
   "source": [
    "## Visualizing the Conv1 Kernels\n",
    "\n",
    "Now, let's visualize the first convolutional layer kernels to see what the network has learned:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd01772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Conv1 kernels\n",
    "plot_conv1_kernels(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3642ddab",
   "metadata": {},
   "source": [
    "## Analysis of Conv1 Kernels\n",
    "\n",
    "The kernels in the first convolutional layer have learned to detect various low-level features:\n",
    "\n",
    "- **Edge detectors**: Kernels that highlight horizontal, vertical, or diagonal edges\n",
    "- **Color detectors**: Kernels that respond to specific colors (red, green, blue patches)\n",
    "- **Texture detectors**: Kernels that respond to specific patterns\n",
    "\n",
    "Each of the 64 filters in the first layer specializes in detecting a particular pattern. These low-level features are then combined in deeper layers to detect more complex patterns such as shapes, textures, and eventually entire objects.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we've:\n",
    "\n",
    "1. Learned about the fundamental building blocks of CNNs (convolution, pooling, and ReLU)\n",
    "2. Understood how these components work together in a CNN architecture\n",
    "3. Implemented AlexNet for CIFAR-10 image classification\n",
    "4. Trained the model and evaluated its performance\n",
    "5. Visualized the learned filters from the first convolutional layer\n",
    "\n",
    "Convolutional Neural Networks have revolutionized computer vision and remain the backbone of many vision-based applications. The principles you've learned in this notebook extend to more modern architectures like VGG, ResNet, and beyond.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
