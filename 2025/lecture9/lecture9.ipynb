{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"j2A-umTSmYN3"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from sklearn.model_selection import ShuffleSplit\n","import os\n","import random\n","import sklearn\n","import pandas as pd\n","import h5py\n","import torch\n","import copy\n","from google.colab import drive\n","\n","\n","SEED = 0\n","torch.manual_seed(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","sklearn.utils.check_random_state(SEED)\n","\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","metadata":{"id":"Cil2f1QXmYN4"},"source":["# Regularization\n","\n","Regularization is a central concept in statistical modeling that helps prevent overfitting and improve generalization. The core idea of regularization is that it adds a penalty term to the loss function which encourages the model to learn simpler patterns.\n","\n","In this notebook, we will explore how regularization works in the context of SVMs and linear regression. We'll do so in three sections:\n","1. As warmup, we'll reimplement an SVM classifier as we did last week\n","2. Exploring the effects of regularization on SVM classifiers for simple, artificial data\n","3. Exploring the effects of regularization on SVM classifiers on real, neural data"]},{"cell_type":"markdown","metadata":{"id":"bBcQfq3tmYN4"},"source":["We'll be using the same UniversalProcedure class from lecture 8. If you closely, you will see some small changes to this class. Don't worry about them for now -- we'll revisit them later."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D1dhLg3VmYN5"},"outputs":[],"source":["# Universal Procedure class from lecture 8\n","class UniversalProcedure:\n","    \"\"\"A class to implement the universal procedure for model training and evaluation.\"\"\"\n","\n","    def __init__(\n","        self, cross_validator, evaluation_metrics={}, loss_func=None, optimizer=None\n","    ):\n","\n","        self.cross_validator = cross_validator\n","        self.evaluation_metrics = evaluation_metrics\n","\n","        if loss_func is None:\n","            self.loss_func = nn.MSELoss()\n","        else:\n","            self.loss_func = loss_func\n","\n","        if optimizer is None:\n","            self.optimizer = optim.Adam\n","        else:\n","            self.optimizer = optimizer\n","\n","    def train(\n","        self,\n","        model,  # The instantiated but untrained PyTorch model\n","        X_train,  # The training data input\n","        y_train,  # The training labels (the desired output)\n","        train_epochs,  # How many epochs to train for\n","        lr,  # The learning rate to use\n","        reg_type, # We'll talk about this later\n","        reg_lambda # We'll talk about this later\n","    ):\n","\n","        # Set up optimizer and loss function from self\n","        optimizer = self.optimizer(model.parameters(), lr=lr)\n","        loss_fn = self.loss_func\n","\n","        # Track losses during training\n","        losses = []\n","\n","        # Training loop\n","        for epoch in range(train_epochs):\n","            # Forward pass\n","            y_pred = model(X_train)  # Gets the prediction\n","\n","            # Compute loss\n","            loss = loss_fn(y_pred, y_train)  # Runs the loss function\n","            losses.append(loss.item())  # Appends the loss for later tracking purposes\n","\n","            # Backward pass and optimize\n","            optimizer.zero_grad()  # To make sure gradients don't accumulate\n","            loss.backward()  # This actually calls the derivation calculation\n","            optimizer.step()  # This actually applies the update\n","\n","        return losses\n","\n","    def evaluate(self, model, x, y, train_epochs=500, lr=0.01, reg_type=\"L2\", reg_lambda=1):\n","\n","        # Initialize results dictionary\n","        results = {}\n","        for name in self.evaluation_metrics.keys():\n","            results[f\"splits_{name}_test\"] = []\n","            results[f\"splits_{name}_train\"] = []\n","\n","        # Get default params from model\n","        original_state_dict = copy.deepcopy(\n","            model.state_dict()\n","        )  # Save initial parameters\n","\n","        # State_dict list to store trained model parameters\n","        state_dicts = []\n","\n","        # Perform cross-validation\n","        for train_idx, test_idx in self.cross_validator.split(x):\n","            # Split data\n","            x_train, x_test = x[train_idx], x[test_idx]\n","            y_train, y_test = y[train_idx], y[test_idx]\n","\n","            # Reset model parameters\n","            model.load_state_dict(original_state_dict)\n","\n","            # Fit model\n","            self.train(model, x_train, y_train, train_epochs, lr, reg_type, reg_lambda)\n","\n","            # Get predictions\n","            with torch.no_grad():\n","                y_test_pred = model.predict(x_test)\n","                y_train_pred = model.predict(x_train)\n","\n","            # Calculate metrics\n","            for name, metric_fn in self.evaluation_metrics.items():\n","                results[f\"splits_{name}_test\"].append(metric_fn(y_test, y_test_pred))\n","                results[f\"splits_{name}_train\"].append(metric_fn(y_train, y_train_pred))\n","            state_dicts.append(copy.deepcopy(model.state_dict()))\n","\n","        # Average metrics across folds\n","        for name in self.evaluation_metrics.keys():\n","            results[f\"{name}_test_mean\"] = np.mean(results[f\"splits_{name}_test\"])\n","            results[f\"{name}_test_std\"] = np.std(results[f\"splits_{name}_test\"])\n","            results[f\"{name}_train_mean\"] = np.mean(results[f\"splits_{name}_train\"])\n","            results[f\"{name}_train_std\"] = np.std(results[f\"splits_{name}_train\"])\n","\n","        return results, state_dicts"]},{"cell_type":"markdown","metadata":{"id":"cjo9KKLmmYN5"},"source":["## I. Implementing an SVM classifier with regularization"]},{"cell_type":"markdown","metadata":{"id":"rXRl2psNmYN5"},"source":["In the first part of this notebook we're going to work with some simple synthetic data. Like the previous lesson, we are going to focus on the problem of classification.\n","\n","Let's take a look at the data we'll be working with:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unDH969FmYN5"},"outputs":[],"source":["def generate_block_data(K):\n","\n","    # Set random seed for reproducibility\n","    torch.manual_seed(SEED)\n","\n","    xp = torch.tensor([-0.5, 1])\n","    dataplus = xp + torch.rand(K, 2)\n","\n","    xm = torch.tensor([-0.5, -2.0])\n","    dataminus = xm + torch.rand(K, 2)\n","\n","    data = torch.cat([dataplus, dataminus], dim=0)\n","    labels = torch.cat([torch.ones(K), -1 * torch.ones(K)])\n","\n","    return data, labels\n","\n","\n","def rotate_block_data(data, ang):\n","\n","    rotation_matrix = torch.tensor([\n","        [torch.cos(torch.tensor(ang)), torch.sin(torch.tensor(ang))],\n","        [-torch.sin(torch.tensor(ang)), torch.cos(torch.tensor(ang))]\n","    ])\n","\n","    data = torch.matmul(data, rotation_matrix)\n","\n","    return data\n","\n","\n","data, labels = generate_block_data(50)\n","data = rotate_block_data(data, 0)\n","\n","dp = data[labels == 1]\n","dm = data[labels == -1]\n","plt.scatter(dp[:, 0], dp[:, -1], color='blue', label='class A')\n","plt.scatter(dm[:, 0], dm[:, -1], color='red', label='class B')\n","plt.xlim(-2, 2)\n","plt.ylim(-2.2, 2.2)\n","plt.legend()\n"]},{"cell_type":"markdown","metadata":{"id":"fZqlweAgmYN6"},"source":["As a warmup exercise, let's reimplement a binary SVM classifier and hinge loss function. This implementation is exactly the same as what we did in the previous notebook, but try and see if you can do it without looking back at your past work!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CfL1Y8-qmYN6"},"outputs":[],"source":["class BinaryLinearSVM(nn.Module):\n","    \"\"\"\n","    Binary linear SVM classifier.\n","    \"\"\"\n","\n","    def __init__(self, input_dim):\n","        \"\"\"\n","        Initialize the SVM model.\n","\n","        Args:\n","            input_dim: Dimensionality of input features\n","        \"\"\"\n","        super(BinaryLinearSVM, self).__init__()\n","\n","        # ---- YOUR CODE HERE ----\n","        # Initialize a linear layer (weights and bias) with nn.Linear\n","        self.linear = ...\n","        # ----------------------\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass to compute SVM scores.\n","\n","        Args:\n","            x: Input features of shape (batch_size, input_dim)\n","\n","        Returns:\n","            SVM scores of shape (batch_size,)\n","        \"\"\"\n","\n","        # ---- YOUR CODE HERE ----\n","        # Compute and return the raw scores\n","        # use .squeeze(1) after applying the linear layer to remove extra dimension\n","        return ...\n","        # ----------------------\n","\n","    def predict(self, x):\n","        \"\"\"\n","        Predict class labels.\n","\n","        Args:\n","            x: features of shape (batch_size, input_dim)\n","\n","        Returns:\n","            Predicted class labels (-1 or 1) of shape (batch_size,)\n","        \"\"\"\n","\n","        # ---- YOUR CODE HERE ----\n","        # apply forward, then...\n","        # HINT: use torch.where to convert all scores <= 0 to torch.tensor(-1.0), and otherwise to torch.tensor(1.0)\n","        # see documentation for torch.where: https://pytorch.org/docs/stable/generated/torch.where.html\n","        return ...\n","        # ----------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lvq1cA5gmYN6"},"outputs":[],"source":["class HingeLoss(nn.Module):\n","    \"\"\"\n","    Hinge loss for binary SVM.\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(HingeLoss, self).__init__()\n","\n","    def forward(self, predictions, targets):\n","        \"\"\"\n","        Compute hinge loss.\n","\n","        Args:\n","            predictions: Raw SVM scores\n","            targets: True labels (-1 or 1)\n","\n","        Returns:\n","            Mean hinge loss\n","        \"\"\"\n","\n","        # ---- YOUR CODE HERE ----\n","        # Calculate margin term: 1 - y * f(x)\n","        margins = ...\n","\n","        # Apply max(0, margin) for each sample\n","        losses = ...\n","\n","        # Return mean loss\n","        mean_loss = ...\n","        # ----------------------\n","\n","        return mean_loss"]},{"cell_type":"markdown","metadata":{"id":"Z0ylsW1bmYN6"},"source":["We also need an evaluation metric for our SVM classifier. We'll use classification accuracy, which is the proportion of correctly classified samples. We provided this metric to you last week, but let's implement it here as well for practice.\n","\n","Complete the code for the binary classification metric below. The formula for calculating accuracy is:\n","\n","$Accuracy = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}} = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{1}(predictions_i = y_i)$\n","\n","where $\\mathbb{1}$ is the indicator function that equals 1 when the condition inside the parentheses is true (prediction matches the actual label) and 0 otherwise. Note that in your implementation you will want to first binarize the predictions and labels to 0 and 1, before computing the accuracy. You can binarize a function x using `x = (x > 0).float()`.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xrPo2XUJmYN6"},"outputs":[],"source":["def classification_accuracy(y, y_pred):\n","    \"\"\"Calculate accuracy for both binary and multi-class cases\"\"\"\n","    if y_pred.dim() == 1:\n","\n","        # ---- YOUR CODE HERE ----\n","        # Binary classification case\n","\n","        # Binarize predictions\n","        predictions = ...\n","\n","        # Binarize labels\n","        y = ...\n","\n","        # Compute and return accuracy\n","        accuracy = ...\n","        return accuracy\n","        # ----------------------\n","\n","    else:\n","        # Multi-class classification case\n","        predictions = torch.argmax(y_pred, dim=1)\n","        return (predictions == y).float().mean()"]},{"cell_type":"markdown","metadata":{"id":"xluN5K-KmYN7"},"source":["Now let's put together a wrapper function that uses our UniversalProcedure class, SVM classifer class, hinge loss class and classification accuracy function to train the SVM classifier on our data:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-D42tbTmYN7"},"outputs":[],"source":["def train_svm(data, labels, n_splits, test_size, train_epochs, lr, reg_type=\"L2\", reg_lambda=1):\n","\n","    # Initialize the SVM model\n","    input_dim = data.shape[1]\n","    svm_model = BinaryLinearSVM(input_dim)\n","\n","    # Create cross-validation splitter\n","    cv_splitter = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=SEED)\n","\n","    # Create UniversalProcedure with hinge loss\n","    hinge_loss = HingeLoss()\n","    procedure = UniversalProcedure(cross_validator=cv_splitter, loss_func=hinge_loss, evaluation_metrics={\"accuracy\": classification_accuracy})\n","\n","    # Train and evaluate\n","    svm_results, svm_state_dicts = procedure.evaluate(\n","        model=svm_model, x=data, y=labels, train_epochs=train_epochs, lr=lr, reg_type=reg_type, reg_lambda=reg_lambda\n","    )\n","\n","    return svm_results, svm_state_dicts\n","\n","svm_results, svm_state_dicts = train_svm(data, labels, n_splits=5, test_size=0.2, train_epochs=1000, lr=0.01)\n","for metric, value in svm_results.items():\n","    if \"test_mean\" in metric:\n","        print(f\"{metric}: {value:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"irk21MfEmYN7"},"source":["And finally let's visualize the decision boundary of the trained model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SO3E4vmPmYN7"},"outputs":[],"source":["svm_model = BinaryLinearSVM(data.shape[1])\n","svm_model.load_state_dict(svm_state_dicts[-1])\n","\n","def plot_hyperplane(data, labels, model, title):\n","\n","    dp = data[labels == 1]\n","    dm = data[labels == -1]\n","    plt.scatter(dp[:, 0], dp[:, -1], color='blue', label='class A')\n","    plt.scatter(dm[:, 0], dm[:, -1], color='red', label='class B')\n","    plt.legend()\n","    plt.xlim(-2, 2)\n","    plt.ylim(-2.2, 2.2)\n","\n","    w0 = model.linear.weight[0, 0].item()\n","    w1 = model.linear.weight[0, 1].item()\n","    intr = model.linear.bias[0].item()\n","    m = -w0 / w1\n","    b = -intr / w1\n","    line = lambda x: m*x + b\n","\n","    # Create a mesh grid for coloring the background\n","    x_min, x_max = plt.xlim()\n","    y_min, y_max = plt.ylim()\n","    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n","                         np.linspace(y_min, y_max, 100))\n","\n","    # Determine which side of the hyperplane each point is on\n","    Z = (xx * w0 + yy * w1 + intr) > 0\n","\n","    # Color the background based on the decision boundary\n","    plt.contourf(xx, yy, Z, alpha=0.2, colors=['lightcoral', 'lightblue'])\n","\n","    # Plot the decision boundary\n","    line0 = line(-2)\n","    line1 = line(2)\n","    plt.plot([-2, 2], [line0, line1], color='k')\n","    plt.xlabel('data axis 0', fontsize=15)\n","    plt.ylabel('data axis 1', fontsize=15)\n","    plt.title(title)\n","\n","plot_hyperplane(data, labels, svm_model, 'Decision Boundary (Unregularized)')"]},{"cell_type":"markdown","metadata":{"id":"ZGptw3m7mYN7"},"source":["Nice! The decision boundary looks pretty reasonable given the data that we generated."]},{"cell_type":"markdown","metadata":{"id":"fumcHuhomYN7"},"source":["But what happens if we add just the tiniest bit of noise to the data?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNeBSrXSmYN7"},"outputs":[],"source":["data, labels = generate_block_data(50)\n","data = rotate_block_data(data, 0)\n","\n","noisy_point_1, new_label_1 = torch.tensor([-0.25, 0.8]).unsqueeze(0), torch.tensor([1])\n","noisy_point_2, new_label_2 = torch.tensor([0.25, -0.8]).unsqueeze(0), torch.tensor([-1])\n","\n","data = torch.cat([data, noisy_point_1, noisy_point_2], dim=0)\n","labels = torch.cat([labels, new_label_1, new_label_2], dim=0)\n","\n","svm_results, svm_state_dicts = train_svm(data, labels, n_splits=5, test_size=0.2, train_epochs=1000, lr=0.01)\n","\n","svm_model = BinaryLinearSVM(data.shape[1])\n","svm_model.load_state_dict(svm_state_dicts[-1])\n","\n","plot_hyperplane(data, labels, svm_model, 'Decision Boundary (Unregularized)')"]},{"cell_type":"markdown","metadata":{"id":"6u2d89tNmYN7"},"source":["That's quite a dramatic shift in the decision boundary, even though we only added two points (that totally conform with the original boundary!).\n","\n","Do you think it makes sense to adjust the decision boundary so much given just two new points? How might we prevent this from happening?\n","\n","Answer: add regularization!"]},{"cell_type":"markdown","metadata":{"id":"M1VsgM4AmYN7"},"source":["## II. Regularizing an SVM classifier for a toy dataset"]},{"cell_type":"markdown","metadata":{"id":"66OGaVcDmYN7"},"source":["#### L2 Regularization\n","\n","First let's try implementing L2 regularization. L2 regularization adds a penalty term to the loss function that is proportional to the square of the magnitude of the weight vector:\n","\n","$L_{reg} = λ * ||w||^2 = λ * Σ(w_i^2)$\n","\n","where:\n","- λ is the regularization strength (hyperparameter)\n","- w is the weight vector\n","- ||w||^2 is the squared L2 norm of the weight vector\n","\n","Let's implement a function that computes the L2 regularization term below. Note that are also including the function definition for L1 regularization below, but we'll implement that later. Note that in all code blocks and markdown cells, we'll be referring to λ as `reg_lambda` in order to avoid confusion with the `lambda` keyword in Python.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xBFT59z9mYN8"},"outputs":[],"source":["def l2_regularization_term(model):\n","\n","    # ---- YOUR CODE HERE ----\n","    # Hint: you can access model weights with model.linear.weight\n","    reg_loss = ...\n","    # ----------------------\n","\n","    return reg_loss\n","\n","def l1_regularization_term(model):\n","    raise NotImplementedError\n"]},{"cell_type":"markdown","metadata":{"id":"N2BpilbGmYN8"},"source":["Now that we have a function to compute the regularization term, we can modify the UniversalProcedure class to use it. Below is a new class definition for UniversalProcedure. It is exactly the same as before, except we have added a new _compute_regularization() function that computes the regularization term.\n","\n","This rewritten class is almost ready to use, but it is missing one important piece: in the training loop, it does not yet update the loss function with the regularization term! Finish the new implementation by adding that functionality below. Specifically, you'll want to add the regularization term scaled by an input parameter reg_lambda to the regular loss function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kRJZNXrrmYN8"},"outputs":[],"source":["class UniversalProcedure:\n","    \"\"\"A class to implement the universal procedure for model training and evaluation.\"\"\"\n","\n","    def __init__(\n","        self, cross_validator, evaluation_metrics={}, loss_func=None, optimizer=None\n","    ):\n","\n","        self.cross_validator = cross_validator\n","        self.evaluation_metrics = evaluation_metrics\n","\n","        if loss_func is None:\n","            self.loss_func = nn.MSELoss()\n","        else:\n","            self.loss_func = loss_func\n","\n","        if optimizer is None:\n","            self.optimizer = optim.Adam\n","        else:\n","            self.optimizer = optimizer\n","\n","    def _compute_regularization(self, model, reg_type):\n","\n","        # Iterate through all model parameters\n","        for param in model.parameters():\n","            if param.requires_grad:\n","                if reg_type == 'L1':\n","                    reg_loss = l1_regularization_term(model)\n","                elif reg_type == 'L2':\n","                    reg_loss = l2_regularization_term(model)\n","                else:\n","                    raise ValueError(f\"Invalid regularization type: {reg_type}\")\n","\n","        return reg_loss\n","\n","    def train(\n","        self,\n","        model,  # The instantiated but untrained PyTorch model\n","        X_train,  # The training data input\n","        y_train,  # The training labels (the desired output)\n","        train_epochs,  # How many epochs to train for\n","        lr,  # The learning rate to use\n","        reg_type,  # NEW: The regularization type to use ('L1' or 'L2')\n","        reg_lambda,  # NEW: The regularization strength\n","    ):\n","\n","        # Set up optimizer and loss function from self\n","        optimizer = self.optimizer(model.parameters(), lr=lr)\n","        loss_fn = self.loss_func\n","\n","        # Track losses during training\n","        losses = []\n","\n","        # Training loop\n","        for epoch in range(train_epochs):\n","            # Forward pass\n","            y_pred = model(X_train)  # Gets the prediction\n","\n","            # Compute loss\n","            loss = loss_fn(y_pred, y_train)  # Runs the loss function\n","\n","            # Add regularization if reg_lambda is specified\n","            if reg_lambda is not None:\n","\n","                # ---- YOUR CODE HERE ----\n","                # Hint: you want to calculate the regularization term and add it to the loss function,\n","                # scaled by reg_lambda\n","                reg_term = ...\n","                loss = ...\n","                # ----------------------\n","\n","            losses.append(loss.item())  # Appends the loss for later tracking purposes\n","\n","            # Backward pass and optimize\n","            optimizer.zero_grad()  # To make sure gradients don't accumulate\n","            loss.backward()  # This actually calls the derivation calculation\n","            optimizer.step()  # This actually applies the update\n","\n","        return losses\n","\n","    def evaluate(self, model, x, y, train_epochs=500, lr=0.01, reg_type=\"L1\", reg_lambda=1):\n","\n","        # Initialize results dictionary\n","        results = {}\n","        for name in self.evaluation_metrics.keys():\n","            results[f\"splits_{name}_test\"] = []\n","            results[f\"splits_{name}_train\"] = []\n","\n","        # Get default params from model\n","        original_state_dict = copy.deepcopy(\n","            model.state_dict()\n","        )  # Save initial parameters\n","\n","        # State_dict list to store trained model parameters\n","        state_dicts = []\n","\n","        # Perform cross-validation\n","        for train_idx, test_idx in self.cross_validator.split(x):\n","            # Split data\n","            x_train, x_test = x[train_idx], x[test_idx]\n","            y_train, y_test = y[train_idx], y[test_idx]\n","\n","            # Reset model parameters\n","            model.load_state_dict(original_state_dict)\n","\n","            # Fit model\n","            self.train(model, x_train, y_train, train_epochs, lr, reg_type, reg_lambda)\n","\n","            # Get predictions\n","            with torch.no_grad():\n","                y_test_pred = model.predict(x_test)\n","                y_train_pred = model.predict(x_train)\n","\n","            # Calculate metrics\n","            for name, metric_fn in self.evaluation_metrics.items():\n","                results[f\"splits_{name}_test\"].append(metric_fn(y_test, y_test_pred))\n","                results[f\"splits_{name}_train\"].append(metric_fn(y_train, y_train_pred))\n","            state_dicts.append(copy.deepcopy(model.state_dict()))\n","\n","        # Average metrics across folds\n","        for name in self.evaluation_metrics.keys():\n","            results[f\"{name}_test_mean\"] = np.mean(results[f\"splits_{name}_test\"])\n","            results[f\"{name}_test_std\"] = np.std(results[f\"splits_{name}_test\"])\n","            results[f\"{name}_train_mean\"] = np.mean(results[f\"splits_{name}_train\"])\n","            results[f\"{name}_train_std\"] = np.std(results[f\"splits_{name}_train\"])\n","\n","        return results, state_dicts"]},{"cell_type":"markdown","metadata":{"id":"Bu1w5tULmYN8"},"source":["Let's see how using L2 regularization affects the decision boundary for the same data as before. Note how we're now calling the train_svm function with reg_lambda=1."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZeUzZ3jlmYN8"},"outputs":[],"source":["data, labels = generate_block_data(50)\n","data = rotate_block_data(data, 0)\n","\n","noisy_point_1, new_label_1 = torch.tensor([-0.25, 0.8]).unsqueeze(0), torch.tensor([1])\n","noisy_point_2, new_label_2 = torch.tensor([0.25, -0.8]).unsqueeze(0), torch.tensor([-1])\n","\n","data = torch.cat([data, noisy_point_1, noisy_point_2], dim=0)\n","labels = torch.cat([labels, new_label_1, new_label_2], dim=0)\n","\n","svm_results, svm_state_dicts = train_svm(data, labels, n_splits=5, test_size=0.2, train_epochs=1000, lr=0.01, reg_lambda=1)\n","\n","svm_model = BinaryLinearSVM(data.shape[1])\n","svm_model.load_state_dict(svm_state_dicts[-1])\n","\n","plot_hyperplane(data, labels, svm_model, 'Decision Boundary (L2 Regularized, C=1)')"]},{"cell_type":"markdown","metadata":{"id":"EXVipJpvmYN8"},"source":["Wow, that's a pretty different line! As we can see, with L2 regularization the fitted decision boundary is now much less sensitive to the noise points that we added.\n","\n","So far we've been using a fixed reg_lambda value of 1. Let's now see how varying reg_lambda affects the decision boundary."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vodr2Bu9mYN8"},"outputs":[],"source":["def plot_hyperplanes(data, labels, models, titles):\n","    fig, axes = plt.subplots(1, len(models), figsize=(7*len(models), 12))\n","\n","    if len(models) == 1:\n","        axes = [axes]\n","\n","    for i, (model, title, ax) in enumerate(zip(models, titles, axes)):\n","        plt.sca(ax)\n","\n","        dp = data[labels == 1]\n","        dm = data[labels == -1]\n","        plt.scatter(dp[:, 0], dp[:, -1], color='blue', label='class A')\n","        plt.scatter(dm[:, 0], dm[:, -1], color='red', label='class B')\n","        plt.legend()\n","        plt.xlim(-2, 2)\n","        plt.ylim(-2.2, 2.2)\n","\n","        w0 = model.linear.weight[0, 0].item()\n","        w1 = model.linear.weight[0, 1].item()\n","        intr = model.linear.bias[0].item()\n","        m = -w0 / w1\n","        b = -intr / w1\n","        line = lambda x: m*x + b\n","\n","        # Create a mesh grid for coloring the background\n","        x_min, x_max = plt.xlim()\n","        y_min, y_max = plt.ylim()\n","        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n","                             np.linspace(y_min, y_max, 100))\n","\n","        # Determine which side of the hyperplane each point is on\n","        Z = (xx * w0 + yy * w1 + intr) > 0\n","\n","        # Color the background based on the decision boundary\n","        plt.contourf(xx, yy, Z, alpha=0.2, colors=['lightcoral', 'lightblue'])\n","\n","        # Plot the decision boundary\n","        line0 = line(-2)\n","        line1 = line(2)\n","        plt.plot([-2, 2], [line0, line1], color='k')\n","        plt.title(title)\n","\n","    for ax in axes:\n","        ax.set_title(ax.get_title(), fontsize=25)\n","\n","    plt.tight_layout()\n","\n","reg_lambdavalues = [0.0001, 0.001, 0.01, 0.1, 1]\n","l2_models = []\n","for reg_lambda in reg_lambdavalues:\n","\n","    svm_results, svm_state_dicts = train_svm(data, labels, n_splits=1, test_size=0.1, train_epochs=1000, lr=0.01, reg_lambda=reg_lambda)\n","\n","    svm_model = BinaryLinearSVM(data.shape[1])\n","    svm_model.load_state_dict(svm_state_dicts[-1])\n","    l2_models.append(copy.deepcopy(svm_model))\n","\n","plot_hyperplanes(data, labels, l2_models, [f\"reg_lambda = {reg_lambda}\" for reg_lambda in reg_lambdavalues])"]},{"cell_type":"markdown","metadata":{"id":"iCBTWvDOmYN8"},"source":["Notice how as we increase C, the decision boundary becomes less and less sensitive to the noise. In other words, as we increase regularization, our model becomes less sensitive to noise.\n"]},{"cell_type":"markdown","metadata":{"id":"5x02pAJEmYN8"},"source":["#### L1 Regularization\n","\n","Now let's implement L1 regularization. L1 regularization follows the same general form as L2 regularization, but instead of penalizing the square of the weights, it penalizes the absolute value of the weights:\n","\n","$L_{reg} = λ * Σ(|w_i|)$\n","\n","Complete the function below to compute the L1 regularization term!\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5jFbdYsLmYN8"},"outputs":[],"source":["def l1_regularization_term(model):\n","\n","    # ---- YOUR CODE HERE ----\n","    # Hint: you can access model weights with model.linear.weight,\n","    # and you can compute the absolute value of the weights with torch.abs()\n","    reg_loss = ...\n","    # ----------------------\n","\n","    return reg_loss"]},{"cell_type":"markdown","metadata":{"id":"8sC8_sGBmYN8"},"source":["Now we can run the same comparison between reg_lambda values as before, but with L1 regularization instead. Note how we're now running the train_svm function with reg_type=\"L1\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9UlWCK68mYN8"},"outputs":[],"source":["reg_lambdavalues = [0.0001, 0.001, 0.01, 0.1, 1]\n","l1_models = []\n","for reg_lambda in reg_lambdavalues:\n","\n","    svm_results, svm_state_dicts = train_svm(data, labels, n_splits=1, test_size=0.2, train_epochs=1000, lr=0.01, reg_lambda=reg_lambda, reg_type=\"L1\")\n","    svm_model = BinaryLinearSVM(data.shape[1])\n","    svm_model.load_state_dict(svm_state_dicts[-1])\n","    l1_models.append(copy.deepcopy(svm_model))\n","\n","plot_hyperplanes(data, labels, l1_models, [f\"reg_lambda = {reg_lambda}\" for reg_lambda in reg_lambdavalues])"]},{"cell_type":"markdown","metadata":{"id":"aNZH8tICmYN9"},"source":["## Regularization on real data\n","\n","Now that we've implemented L1 and L2 regularization, let's graduate to some real data. Specifically, we're going to use the same IT cortex data as in the previous notebook.\n","\n","Previously we learned to fit classifiers to this data, and this time we're going to fit regularized classifiers. Fitting regularized classifiers on this set of real data rather than our synthetic toy data will allow us to explore two subtlies of regularization: first, how regularization can help us fit models that generalize better to test data, and second, how L1 and L2 regularization differ.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H5UGyWMhmYN9"},"outputs":[],"source":["# Load the neural data\n","LECTURE_DIRECTORY = \"/content/drive/MyDrive/psych254a_2025/data\"\n","\n","# Load the neural data\n","neural_data_file = os.path.join(LECTURE_DIRECTORY, \"ventral_neural_data.hdf5\")\n","ventral_dataset = h5py.File(neural_data_file, \"r\")\n","\n","neural_data = torch.tensor(ventral_dataset['time_averaged_trial_averaged'][:])\n","meta_data = pd.DataFrame({\n","    key: [s.decode('utf-8') if isinstance(s, bytes) else s\n","          for s in ventral_dataset['image_meta'][key][:]]\n","    for key in ventral_dataset['image_meta'].keys()\n","})"]},{"cell_type":"markdown","metadata":{"id":"n3Sz38ymmYN9"},"source":["First let's evaluate the performance of the SVM classifier on a boats vs cars task without regularization. To turn off regularization, we can set reg_lambda to 0. Let's complete the function below to evaluate SVM classifier performance for different values of reg_lambda."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYRT5b82mYN9"},"outputs":[],"source":["def evaluate_svm_classifier(reg_lambda, reg_type, cat1, cat2, vl, n_splits=5, test_size=0.2, train_epochs=1000, lr=0.01):\n","\n","    # Prepare data\n","    mdata = meta_data[(meta_data[\"variation_level\"] == vl) & (meta_data[\"category\"].isin([cat1, cat2]))]\n","    ndata = neural_data[mdata.index] # These are our input features\n","    labels = mdata[\"category\"].reset_index(drop=True)\n","    label_mapping = {cat1: 1, cat2: -1}\n","    labels = torch.tensor(labels.map(label_mapping)) # These are our labels\n","\n","    # ---- YOUR CODE HERE ----\n","    # Initialize the SVM model\n","    svm_model = ...\n","\n","    # Create cross-validation splitter -- use a seed for reproducibility!\n","    cv_splitter = ...\n","\n","    # Create UniversalProcedure with hinge loss\n","    procedure = ...\n","\n","    # Train and evaluate\n","    svm_results, svm_state_dicts = ...\n","    # ----------------------\n","\n","    print('SVM Classifier Regularization reg_lambda = %s Var level %s train performance on %s vs %s: %.2f%%' % (\n","        reg_lambda,\n","        vl,\n","        cat1,\n","        cat2,\n","        100*svm_results['accuracy_train_mean'])\n","    )\n","    print('SVM Classifier Regularization reg_lambda = %s Var level %s test performance on %s vs %s: %.2f%%' % (\n","        reg_lambda,\n","        vl,\n","        cat1,\n","        cat2,\n","        100*svm_results['accuracy_test_mean'])\n","    )\n","    print()\n","\n","\n","for vl in ['V0', 'V3', 'V6']:\n","    evaluate_svm_classifier(reg_lambda=0, reg_type=\"L2\", cat1=\"Boats\", cat2=\"Cars\", vl=vl)"]},{"cell_type":"markdown","metadata":{"id":"ucxJtdE1mYN9"},"source":["Now let's see what happens when we add just a bit of L2 regularization, with reg_lambda=0.01"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8sD70QVmYOH"},"outputs":[],"source":["for vl in ['V0', 'V3', 'V6']:\n","    evaluate_svm_classifier(reg_lambda=0.01, reg_type=\"L2\", cat1=\"Boats\", cat2=\"Cars\", vl=vl)"]},{"cell_type":"markdown","metadata":{"id":"nxQJcru8mYOH"},"source":["Notice how when we add regularization, train performance *decreases* relative to no regularization, while test performance *increases* relative to no regularization. In other words, regularization is helping to prevent overfitting, and is thus helping the model generalize better to test data.\n","\n","We can visualize this more clearly by plotting the mean and standard deviation of training and test accuracy as we vary reg_lambda:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fB_s9p-fmYOH"},"outputs":[],"source":["reg_lambdavalues = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4]\n","\n","def fit_svm_classifiers(cat1, cat2, vl, reg_type, reg_lambdavalues):\n","    rows = []\n","    for reg_lambda in tqdm(reg_lambdavalues):\n","        mdata = meta_data[(meta_data[\"variation_level\"] == vl) & (meta_data[\"category\"].isin([cat1, cat2]))]\n","        ndata = neural_data[mdata.index]\n","        labels = mdata[\"category\"].reset_index(drop=True)\n","        label_mapping = {cat1: 1, cat2: -1}\n","        labels = torch.tensor(labels.map(label_mapping))\n","\n","        svm_results, svm_state_dicts = train_svm(ndata, labels, n_splits=5, test_size=0.2, train_epochs=400, lr=0.01, reg_lambda=reg_lambda, reg_type=reg_type)\n","\n","        weights = []\n","        for state_dict in svm_state_dicts:\n","            weight_tensor = state_dict['linear.weight']\n","            weight_values = weight_tensor.numpy().flatten()\n","            weights.extend(weight_values)\n","\n","        rows.append({\n","            \"reg_type\": reg_type,\n","            \"reg_lambda\": reg_lambda,\n","            \"mean_train_acc\": svm_results['accuracy_train_mean'],\n","            \"mean_test_acc\": svm_results['accuracy_test_mean'],\n","            \"std_train_acc\": svm_results['accuracy_train_std'],\n","            \"std_test_acc\": svm_results['accuracy_test_std'],\n","            \"weights\": weights\n","        })\n","    df = pd.DataFrame(rows)\n","    return df\n","\n","\n","reg_type = \"L2\"\n","cat1 = \"Boats\"\n","cat2 = \"Cars\"\n","vl = \"V6\"\n","df = fit_svm_classifiers(cat1, cat2, vl, reg_type, reg_lambdavalues)\n","plt.figure(figsize=(10, 6))\n","plt.errorbar(df['reg_lambda'], df['mean_train_acc'], yerr=df['std_train_acc'], marker='o', label='Train Accuracy')\n","plt.errorbar(df['reg_lambda'], df['mean_test_acc'], yerr=df['std_test_acc'], marker='s', label='Test Accuracy')\n","plt.xscale('log')\n","plt.xlabel('reg_lambda (regularization strength)')\n","plt.ylabel('Accuracy')\n","plt.title(f'SVM Performance with {reg_type} Regularization ({cat1} vs {cat2}, {vl})')\n","plt.grid(True, alpha=0.3)\n","plt.legend()\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"svtBbonomYOH"},"source":["Note how we can use this to pick an optimal level of regularization for our model -- in this case, reg_lambda=0.01 or 0.1 seem to be a good choices for classification at the V6 level, since that is the choice that maximizes test accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XndFD0CumYOH"},"outputs":[],"source":["reg_type = \"L1\"\n","cat1 = \"Boats\"\n","cat2 = \"Cars\"\n","vl = \"V6\"\n","df = fit_svm_classifiers(cat1, cat2, vl, reg_type, reg_lambdavalues)\n","plt.figure(figsize=(10, 6))\n","plt.errorbar(df['reg_lambda'], df['mean_train_acc'], yerr=df['std_train_acc'], marker='o', label='Train Accuracy')\n","plt.errorbar(df['reg_lambda'], df['mean_test_acc'], yerr=df['std_test_acc'], marker='s', label='Test Accuracy')\n","plt.xscale('log')\n","plt.xlabel('reg_lambda (regularization strength)')\n","plt.ylabel('Accuracy')\n","plt.title(f'SVM Performance with {reg_type} Regularization ({cat1} vs {cat2}, {vl})')\n","plt.grid(True, alpha=0.3)\n","plt.legend()\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"fwb931_JmYOH"},"source":["The same applies to L1 regularization as well!"]},{"cell_type":"markdown","metadata":{"id":"QmsmwFRXmYOH"},"source":["#### Comparing L1 and L2 Regularization"]},{"cell_type":"markdown","metadata":{"id":"Wb33woEYmYOH"},"source":["Finally, you might be asking: how are L1 and L2 regularization different? The results you've seen so far don't demonstrate particularly meaningful differences.\n","\n","One important way that L1 and L2 regularization are different is that L1 regularization tends to produce sparse solutions, while L2 regularization tends to produce dense solutions.\n","\n","To see this, let's compare the weights of models that are fit with L1 and L2 regularization.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8G03auWmYOH"},"outputs":[],"source":["l1_df = fit_svm_classifiers(\"Boats\", \"Cars\", \"V6\", \"L1\", reg_lambdavalues)\n","l2_df = fit_svm_classifiers(\"Boats\", \"Cars\", \"V6\", \"L2\", reg_lambdavalues)\n","df = pd.concat([l1_df, l2_df])\n","reg_lambda = 0.01\n","\n","\n","plt.figure(figsize=(10, 6))\n","for reg, color, alpha in [(\"L1\", \"blue\", 0.5), (\"L2\", \"green\", 0.5)]:\n","    # Filter dataframe for this regularization type\n","    reg_df = df[df[\"reg_type\"] == reg]\n","\n","    # Get weights for this reg_lambda value\n","    weights = reg_df[reg_df[\"reg_lambda\"] == reg_lambda].iloc[0][\"weights\"]\n","\n","    # Plot histogram of weights\n","    plt.hist(weights, bins=30, alpha=alpha, color=color, label=reg)\n","\n","# Add vertical line at 0\n","plt.axvline(x=0, color='r', linestyle='--', alpha=0.5)\n","\n","plt.title(f\"reg_lambda={reg_lambda}\")\n","plt.xlabel(\"Weight Value\")\n","plt.ylabel(\"Frequency\")\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.suptitle(\"Weight Distribution: L1 vs L2 Regularization (reg_lambda=0.01)\", y=1.02, fontsize=16)\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"yuvt-3h1mYOH"},"source":["As we can see, in the case of reg_lambda=0.01, a very large number of weights are roughly zero for L1 but not L2. This means that the L1 regularized solution is *sparser* than the L2 regularized solution.\n","\n","Why? This is because L1 regularization penalizes the absolute value of the weights, while L2 regularization penalizes the square of the weights. As a result, the pressure to minimize a weight to zero is constant for L1 but weakens as the weight approaches zero for L2. Thus, L1 regularization is more likely to push weights to zero than L2 regularization."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-4qAycQ9mYOH"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"research","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}